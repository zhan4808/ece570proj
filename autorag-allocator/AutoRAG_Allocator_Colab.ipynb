{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AutoRAG-Allocator - Google Colab Setup\n",
        "\n",
        "Budget-aware model assignment for compound RAG pipelines.\n",
        "\n",
        "**Requirements**: Colab Pro with A100 GPU (recommended)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Clone from GitHub (if public repo)\n",
        "# !git clone https://github.com/yourusername/ece570proj.git\n",
        "\n",
        "# Option 2: Upload files manually\n",
        "# If repo is private, use: File > Upload to upload the autorag-allocator folder\n",
        "# Then uncomment the line below:\n",
        "# %cd /content/autorag-allocator\n",
        "\n",
        "# For now, let's set up the directory structure\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Check for project in common locations (including nested structure)\n",
        "possible_paths = [\n",
        "    Path('/content/autorag-allocator/ece570proj/autorag-allocator'),  # Nested structure\n",
        "    Path('/content/autorag-allocator'),  # Direct upload\n",
        "    Path('/content/ece570proj/autorag-allocator'),  # Git clone\n",
        "]\n",
        "\n",
        "project_dir = None\n",
        "for path in possible_paths:\n",
        "    if path.exists() and (path / 'requirements.txt').exists():\n",
        "        project_dir = path\n",
        "        break\n",
        "\n",
        "if project_dir:\n",
        "    os.chdir(project_dir)\n",
        "    print(f\"‚úÖ Found project at: {project_dir}\")\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "else:\n",
        "    # Create default directory\n",
        "    project_dir = Path('/content/autorag-allocator')\n",
        "    project_dir.mkdir(exist_ok=True)\n",
        "    os.chdir(project_dir)\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "    print(\"\\nüìÅ Please upload your autorag-allocator folder to /content/\")\n",
        "    print(\"   Or clone from GitHub if your repo is public\")\n",
        "    print(\"\\n   To upload: Use Colab's file browser (üìÅ icon) > Upload\")\n",
        "\n",
        "# Check if we have the files\n",
        "if project_dir and (project_dir / 'requirements.txt').exists():\n",
        "    print(\"\\n‚úÖ Found requirements.txt, installing dependencies...\")\n",
        "    %pip install -q -r requirements.txt\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  requirements.txt not found. Please upload files first.\")\n",
        "    print(\"   Expected locations:\")\n",
        "    print(\"   - /content/autorag-allocator/ece570proj/autorag-allocator/requirements.txt\")\n",
        "    print(\"   - /content/autorag-allocator/requirements.txt\")\n",
        "    print(\"   - /content/ece570proj/autorag-allocator/requirements.txt\")\n",
        "\n",
        "# Install FAISS (Colab-compatible version)\n",
        "# Note: faiss-gpu might not be available in all Colab environments\n",
        "# We'll try faiss-gpu first, fall back to faiss-cpu if needed\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"\\nInstalling FAISS...\")\n",
        "result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"faiss-gpu\"], \n",
        "                       capture_output=True, text=True)\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úÖ Installed faiss-gpu\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  faiss-gpu not available, installing faiss-cpu (works fine in Colab)\")\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"faiss-cpu\"], \n",
        "                  check=False)\n",
        "    print(\"‚úÖ Installed faiss-cpu\")\n",
        "\n",
        "print(\"\\n‚úÖ Installation complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configure API Keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Method 1: Use Colab secrets (recommended)\n",
        "try:\n",
        "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
        "    os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')  # For Llama models\n",
        "    print(\"‚úÖ API keys loaded from Colab secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not load from secrets: {e}\")\n",
        "    print(\"Using direct assignment instead...\")\n",
        "    # Method 2: Set directly (less secure, but works)\n",
        "    # os.environ['OPENAI_API_KEY'] = 'sk-...'\n",
        "    # os.environ['GROQ_API_KEY'] = 'gsk_...'\n",
        "    # os.environ['HF_TOKEN'] = 'hf_...'\n",
        "\n",
        "# Verify\n",
        "has_openai = bool(os.getenv('OPENAI_API_KEY'))\n",
        "has_groq = bool(os.getenv('GROQ_API_KEY'))\n",
        "has_hf = bool(os.getenv('HF_TOKEN'))\n",
        "print(f\"\\nAPI Keys Status:\")\n",
        "print(f\"  OPENAI_API_KEY: {'‚úÖ Set' if has_openai else '‚ùå Missing'}\")\n",
        "print(f\"  GROQ_API_KEY: {'‚úÖ Set' if has_groq else '‚ùå Missing'}\")\n",
        "print(f\"  HF_TOKEN: {'‚úÖ Set' if has_hf else '‚ùå Missing'}\")\n",
        "\n",
        "if not (has_openai and has_groq):\n",
        "    print(\"\\n‚ö†Ô∏è  Please set API keys using Colab secrets (üîë icon in sidebar)\")\n",
        "if not has_hf:\n",
        "    print(\"‚ö†Ô∏è  HF_TOKEN not set - local Llama models will use API fallback\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print(f\"GPU Memory: {props.total_memory / 1e9:.1f} GB\")\n",
        "    print(f\"‚úÖ GPU ready for FAISS acceleration\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected\")\n",
        "    print(\"Go to: Runtime > Change runtime type > GPU (A100)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Login to HuggingFace (for Llama models)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to HuggingFace (required for Llama models)\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = os.getenv('HF_TOKEN')\n",
        "if hf_token:\n",
        "    try:\n",
        "        login(token=hf_token)\n",
        "        print(\"‚úÖ HuggingFace login successful!\")\n",
        "        print(\"   Local Llama models will be available\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  HuggingFace login failed: {e}\")\n",
        "        print(\"   Local models will fall back to API\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  HF_TOKEN not set - skipping HuggingFace login\")\n",
        "    print(\"   Local Llama models will use API fallback\")\n",
        "    print(\"   To enable local models: Set HF_TOKEN in Colab secrets (üîë icon)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Test Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project to path (check nested structure first)\n",
        "project_paths = [\n",
        "    '/content/autorag-allocator/ece570proj/autorag-allocator',  # Nested structure\n",
        "    '/content/autorag-allocator',  # Direct upload\n",
        "    '/content/ece570proj/autorag-allocator',  # Git clone\n",
        "    os.getcwd()\n",
        "]\n",
        "\n",
        "for path in project_paths:\n",
        "    if Path(path).exists() and (Path(path) / 'src').exists():\n",
        "        sys.path.insert(0, path)\n",
        "        print(f\"‚úÖ Added {path} to Python path\")\n",
        "        break\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Could not find project directory. Please ensure files are uploaded.\")\n",
        "\n",
        "# Test corpus loading (small sample)\n",
        "try:\n",
        "    from src.data.corpus import load_wikipedia_corpus\n",
        "    \n",
        "    print(\"\\nTesting corpus loading (100 passages)...\")\n",
        "    corpus = load_wikipedia_corpus(n_passages=100, seed=42)\n",
        "    print(f\"‚úÖ Loaded {len(corpus)} passages\")\n",
        "    print(f\"Sample: {corpus[0][:150]}...\")\n",
        "except ImportError as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  Could not import corpus loader: {e}\")\n",
        "    print(\"   This might be a path issue. Will work during full experiment.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  Error loading corpus: {e}\")\n",
        "    print(\"   This is okay for now - will work during full experiment\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Run Full Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Find project directory (check nested structure first)\n",
        "project_paths = [\n",
        "    '/content/autorag-allocator/ece570proj/autorag-allocator',  # Nested structure\n",
        "    '/content/autorag-allocator',  # Direct upload\n",
        "    '/content/ece570proj/autorag-allocator',  # Git clone\n",
        "    os.getcwd()\n",
        "]\n",
        "\n",
        "project_dir = None\n",
        "for path in project_paths:\n",
        "    if Path(path).exists() and (Path(path) / 'src').exists():\n",
        "        project_dir = path\n",
        "        # Add to path BEFORE any imports\n",
        "        if path not in sys.path:\n",
        "            sys.path.insert(0, path)\n",
        "        break\n",
        "\n",
        "if not project_dir:\n",
        "    raise RuntimeError(\"Could not find project directory. Please upload files first.\")\n",
        "\n",
        "# Change directory BEFORE imports\n",
        "os.chdir(project_dir)\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(f\"Python path includes: {[p for p in sys.path if 'autorag' in p or 'ece570' in p]}\")\n",
        "\n",
        "# Verify src.models can be imported BEFORE importing run_experiments\n",
        "try:\n",
        "    import src.models\n",
        "    print(f\"‚úÖ src.models module found\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Cannot import src.models: {e}\")\n",
        "    print(f\"   Checking if src/models exists...\")\n",
        "    models_dir = Path(project_dir) / 'src' / 'models'\n",
        "    print(f\"   {models_dir} exists: {models_dir.exists()}\")\n",
        "    if models_dir.exists():\n",
        "        print(f\"   Contents: {list(models_dir.glob('*.py'))}\")\n",
        "    raise\n",
        "\n",
        "# Set corpus size (1000 for testing, 10000 for full experiment)\n",
        "corpus_size = 10000  # Change to 1000 for quick test\n",
        "os.environ['CORPUS_SIZE'] = str(corpus_size)\n",
        "\n",
        "print(f\"\\nRunning experiment with corpus size: {corpus_size}\")\n",
        "print(\"This may take 30-45 minutes for full corpus...\\n\")\n",
        "\n",
        "# Import AFTER setting path and directory\n",
        "from experiments.run_experiments import main\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: View Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Find results file in common locations (including nested structure)\n",
        "results_paths = [\n",
        "    Path('/content/autorag-allocator/ece570proj/autorag-allocator/results/full_results.json'),  # Nested\n",
        "    Path('/content/autorag-allocator/results/full_results.json'),  # Direct\n",
        "    Path('/content/ece570proj/autorag-allocator/results/full_results.json'),  # Git clone\n",
        "    Path(os.getcwd()) / 'results' / 'full_results.json'  # Current dir\n",
        "]\n",
        "\n",
        "results_file = None\n",
        "for path in results_paths:\n",
        "    if path.exists():\n",
        "        results_file = path\n",
        "        break\n",
        "\n",
        "if results_file and results_file.exists():\n",
        "    with open(results_file, 'r') as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    print(\"=== Experiment Results ===\\n\")\n",
        "    \n",
        "    # NQ-Open Baseline\n",
        "    nq_base = results.get('nq_baseline', {})\n",
        "    print(f\"NQ-Open Baseline:\")\n",
        "    print(f\"  EM: {nq_base.get('em', 0):.1f}%\")\n",
        "    print(f\"  F1: {nq_base.get('f1', 0):.1f}%\")\n",
        "    print(f\"  Cost: {nq_base.get('cost_cents', 0):.2f}¬¢/query\")\n",
        "    print(f\"  Latency: {nq_base.get('latency_ms', 0):.0f}ms\\n\")\n",
        "    \n",
        "    # NQ-Open Adaptive\n",
        "    nq_adapt = results.get('nq_adaptive', {})\n",
        "    best = nq_adapt.get('best', {})\n",
        "    if best:\n",
        "        config = best.get('config', {})\n",
        "        print(f\"NQ-Open Adaptive (Best):\")\n",
        "        print(f\"  Config: {config.get('R', '?')}/{config.get('G', '?')}/{config.get('V', '?')}\")\n",
        "        print(f\"  EM: {best.get('em', 0):.1f}%\")\n",
        "        print(f\"  F1: {best.get('f1', 0):.1f}%\")\n",
        "        print(f\"  Cost: {best.get('cost_cents', 0):.2f}¬¢/query\")\n",
        "        print(f\"  Latency: {best.get('latency_ms', 0):.0f}ms\\n\")\n",
        "        \n",
        "        # Improvement\n",
        "        em_improve = best.get('em', 0) - nq_base.get('em', 0)\n",
        "        cost_improve = nq_base.get('cost_cents', 0) - best.get('cost_cents', 0)\n",
        "        print(f\"Improvement:\")\n",
        "        print(f\"  EM: +{em_improve:.1f}%\")\n",
        "        print(f\"  Cost: -{cost_improve:.2f}¬¢/query\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Results file not found. Run experiment first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Generate Figures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Find project directory (check nested structure first)\n",
        "project_paths = [\n",
        "    '/content/autorag-allocator/ece570proj/autorag-allocator',  # Nested structure\n",
        "    '/content/autorag-allocator',  # Direct upload\n",
        "    '/content/ece570proj/autorag-allocator',  # Git clone\n",
        "    os.getcwd()\n",
        "]\n",
        "\n",
        "for path in project_paths:\n",
        "    if Path(path).exists() and (Path(path) / 'src').exists():\n",
        "        sys.path.insert(0, path)\n",
        "        break\n",
        "\n",
        "try:\n",
        "    from experiments.generate_figures import main as gen_figures\n",
        "    \n",
        "    print(\"Generating figures...\")\n",
        "    gen_figures()\n",
        "    print(\"‚úÖ Figures saved to results/ directory\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not import figure generator: {e}\")\n",
        "    print(\"   Make sure experiments/generate_figures.py exists\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Error generating figures: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Download Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Find results directory (including nested structure)\n",
        "results_dirs = [\n",
        "    Path('/content/autorag-allocator/ece570proj/autorag-allocator/results'),  # Nested\n",
        "    Path('/content/autorag-allocator/results'),  # Direct\n",
        "    Path('/content/ece570proj/autorag-allocator/results'),  # Git clone\n",
        "    Path(os.getcwd()) / 'results'  # Current dir\n",
        "]\n",
        "\n",
        "results_dir = None\n",
        "for dir_path in results_dirs:\n",
        "    if dir_path.exists():\n",
        "        results_dir = dir_path\n",
        "        break\n",
        "\n",
        "if results_dir:\n",
        "    # Download results JSON\n",
        "    results_file = results_dir / 'full_results.json'\n",
        "    if results_file.exists():\n",
        "        files.download(str(results_file))\n",
        "        print(f\"‚úÖ Downloaded {results_file.name}\")\n",
        "    \n",
        "    # Download figures\n",
        "    for fig_file in ['results_comparison.pdf', 'pareto_frontier.pdf', 'profiling_overhead.pdf']:\n",
        "        fig_path = results_dir / fig_file\n",
        "        if fig_path.exists():\n",
        "            files.download(str(fig_path))\n",
        "            print(f\"‚úÖ Downloaded {fig_file}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Downloads initiated\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Results directory not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitor Resources\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check disk usage\n",
        "!df -h /content\n",
        "\n",
        "# Check GPU memory\n",
        "!nvidia-smi\n",
        "\n",
        "# List cached files (check common locations)\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "cache_dirs = [\n",
        "    Path('/content/autorag-allocator/ece570proj/autorag-allocator/data/cache'),  # Nested\n",
        "    Path('/content/autorag-allocator/data/cache'),  # Direct\n",
        "    Path('/content/ece570proj/autorag-allocator/data/cache'),  # Git clone\n",
        "    Path(os.getcwd()) / 'data' / 'cache'  # Current dir\n",
        "]\n",
        "\n",
        "for cache_dir in cache_dirs:\n",
        "    if cache_dir.exists():\n",
        "        print(f\"\\nCache directory: {cache_dir}\")\n",
        "        !ls -lh {cache_dir}\n",
        "        break\n",
        "else:\n",
        "    print(\"\\nNo cache directory found yet\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
